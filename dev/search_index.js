var documenterSearchIndex = {"docs":
[{"location":"man/welch_fisher/#Welch-ANOVA-and-Fisher-RxC-Tests","page":"Welch ANOVA & Fisher RxC","title":"Welch ANOVA & Fisher RxC Tests","text":"","category":"section"},{"location":"man/welch_fisher/#Welch's-ANOVA","page":"Welch ANOVA & Fisher RxC","title":"Welch's ANOVA","text":"Standard One-Way ANOVA assumes that all groups share a common variance (homoscedasticity). When this assumption is violated, the Type I error rate can inflate significantly.\n\nHypothesisTestsExtra implements Welch's ANOVA, which weights observations by the inverse of their group variance. The test statistic F follows an approximate F-distribution with degrees of freedom df_1 and df_2 calculated via the Welch-Satterthwaite equation.","category":"section"},{"location":"man/welch_fisher/#Usage","page":"Welch ANOVA & Fisher RxC","title":"Usage","text":"# Vector of vectors\nWelchANOVATest(group_a, group_b, group_c)\n\n# DataFrame\nWelchANOVATest(df, :GroupCol, :ValueCol)","category":"section"},{"location":"man/welch_fisher/#Fisher's-Exact-Test-(R-\\times-C)","page":"Welch ANOVA & Fisher RxC","title":"Fisher's Exact Test (R times C)","text":"The standard FisherExactTest is typically limited to 2 times 2 contingency tables due to the computational complexity of calculating exact factorials for larger matrices.\n\nHypothesisTestsExtra introduces FisherExactTestRxC, which automatically selects the best strategy:\n\n2x2 Tables: Dispatches to the exact method.\nRxC Tables: Uses a Monte Carlo (MC) simulation strategy.","category":"section"},{"location":"man/welch_fisher/#Algorithm","page":"Welch ANOVA & Fisher RxC","title":"Algorithm","text":"For tables larger than 2 times 2, we estimate the p-value by sampling random tables with the same marginal totals as the observed table.\n\nStatistic: Log-probability of the table configuration.\nP-Value: Proportion of simulated tables with a probability less than or equal to the observed table's probability.\nSmoothing: Applies the (k+1)(N+1) rule to prevent zero p-values.","category":"section"},{"location":"man/welch_fisher/#Usage-2","page":"Welch ANOVA & Fisher RxC","title":"Usage","text":"using HypothesisTestsExtra\n\n# 3x3 Contingency Table\ntbl = [10 5 2; 2 15 8; 1 4 20]\n\n# Automatically detects size and uses Monte Carlo\ntest = FisherExactTestRxC(tbl)\n\n# Get p-value and Confidence Interval of the simulation\npvalue(test; n_sim=100_000)\nconfint(test) ","category":"section"},{"location":"man/posthoc_theory/#Post-Hoc-Analysis-Guide","page":"Post-Hoc Analysis Guide","title":"Post-Hoc Analysis Guide","text":"Post-hoc tests are performed after a significant omnibus test (like ANOVA or Chi-Square) to determine which specific groups or categories differ. ","category":"section"},{"location":"man/posthoc_theory/#1.-Parametric-Post-Hoc-Tests","page":"Post-Hoc Analysis Guide","title":"1. Parametric Post-Hoc Tests","text":"Function: PostHocTest\n\nThese methods assume normality. Choice depends on variance assumptions and the desired balance between Type I errors (False Positives) and Type II errors (False Negatives).\n\nMethod Variance Assumption Conservatism Description\n:tukey Equal Balanced Recommended default. Controls FWER (Family-Wise Error Rate) exactly for all pairwise comparisons. Best for balanced designs.\n:bonferroni Equal Very High Simple alpha  m correction. Can be overly conservative if the number of pairs is large.\n:lsd Equal Low Fisher's Least Significant Difference. No correction applied. High power but high Type I error risk. Only use if ANOVA F-test is very strong.\n:scheffe Equal High Designed for any linear contrast, not just pairwise. Very conservative for simple pairwise tests.\n:sidak Equal High Slightly more powerful version of Bonferroni.\n:tamhane Unequal Balanced Use after Welch ANOVA. Uses the T2 statistic and approximates degrees of freedom for every pair. Robust to heteroscedasticity.","category":"section"},{"location":"man/posthoc_theory/#Example","page":"Post-Hoc Analysis Guide","title":"Example","text":"# If Levene's test failed, use Tamhane:\nPostHocTest(groups; method=:tamhane)","category":"section"},{"location":"man/posthoc_theory/#2.-Non-Parametric-Post-Hoc-Tests","page":"Post-Hoc Analysis Guide","title":"2. Non-Parametric Post-Hoc Tests","text":"Function: PostHocNonPar\n\nUsed when data is ordinal or normality is violated (e.g., after Kruskal-Wallis).","category":"section"},{"location":"man/posthoc_theory/#Methods","page":"Post-Hoc Analysis Guide","title":"Methods","text":":dunn_bonferroni (Default): Uses rank sums (Z-scores) and adjusts p-values using Bonferroni.\n:nemenyi: The non-parametric equivalent of Tukey's HSD. Tests the difference in rank sums against a critical range from the Studentized Range distribution.","category":"section"},{"location":"man/posthoc_theory/#3.-Contingency-Table-Post-Hoc","page":"Post-Hoc Analysis Guide","title":"3. Contingency Table Post-Hoc","text":"Functions: PostHocContingencyRow, PostHocContingencyCell\n\nWhen a Chi-Square test is significant, you need to know which rows or specific cells are driving the association.","category":"section"},{"location":"man/posthoc_theory/#A.-Row-wise-Comparisons-(PostHocContingencyRow)","page":"Post-Hoc Analysis Guide","title":"A. Row-wise Comparisons (PostHocContingencyRow)","text":"Compares distributions between pairs of rows (groups).\n\nMethod :chisq: Performs a 2 times C Chi-square test for every pair of rows.\nMethod :fisher: Performs a 2 times C Fisher test for every pair.\nAdjustment: P-values are adjusted (e.g., Bonferroni, FDR) to account for multiple testing.","category":"section"},{"location":"man/posthoc_theory/#B.-Cell-wise-Residuals-(PostHocContingencyCell)","page":"Post-Hoc Analysis Guide","title":"B. Cell-wise Residuals (PostHocContingencyCell)","text":"Identifies specific cells that are over- or under-represented.\n\nMethod :asr (Adjusted Standardized Residuals): Calculates the residual r_ij = (O - E)  sqrtE(1-row)(1-col).\nIf r_ij  Z_alpha2 (approx 1.96 for alpha=005), the cell is significant.\nProvides a detailed breakdown of which specific intersection (Row times Col) deviates from independence.","category":"section"},{"location":"man/posthoc_theory/#Compact-Letter-Display-(CLD)","page":"Post-Hoc Analysis Guide","title":"Compact Letter Display (CLD)","text":"All group-level post-hoc tests support cld=true. This generates a string representation where groups sharing the same letter are not significantly different.\n\n# 3 groups with different distributions\n  g1 = rand(10)\n  g2 = rand(10) .+ 2\n  g3 = rand(10) .+ 0.5\n  \n# Perform Dunn's test with Bonferroni correction and generate CLD letters\nresult = PostHocNonPar([g1, g2, g3]; method=:dunn_bonferroni, cld=true, row_labels=[\"Ctrl\", \"TrtA\", \"TrtB\"])\n\nYou will get:\n\n------------------------------\nPost-hoc Test: :dunn_bonferroni (alpha=0.05)\n------------------------------\n\nCompact Letter Display (Means sorted descending):\n┌────────────┬────────────┬────────┐\n│ GroupIndex │ GroupLabel │    CLD │\n│      Int64 │     String │ String │\n├────────────┼────────────┼────────┤\n│          1 │       Ctrl │      b │\n│          2 │       TrtA │      a │\n│          3 │       TrtB │      b │\n└────────────┴────────────┴────────┘\n\nPairwise Comparisons:\n┌─────────────┬─────────┬─────────┬─────────┬──────────┬────────────┬───────────┬───────────┬────────┬─────────────────┐\n│    Contrast │    Diff │ Std.Err │    Stat │ Critical │    P-value │ Lower 95% │ Upper 95% │    Sig │            Note │\n│      String │ Float64 │ Float64 │ Float64 │  Float64 │    Float64 │   Float64 │   Float64 │ String │          String │\n├─────────────┼─────────┼─────────┼─────────┼──────────┼────────────┼───────────┼───────────┼────────┼─────────────────┤\n│ Ctrl - TrtA │   -19.6 │   3.937 │  4.9784 │  2.39398 │ 1.92331e-6 │  -29.0251 │  -10.1749 │      * │ Adj: Bonferroni │\n│ Ctrl - TrtB │    -9.2 │   3.937 │  2.3368 │  2.39398 │  0.0583484 │  -18.6251 │  0.225108 │        │ Adj: Bonferroni │\n│ TrtA - TrtB │    10.4 │   3.937 │  2.6416 │  2.39398 │  0.0247544 │  0.974892 │   19.8251 │      * │ Adj: Bonferroni │\n└─────────────┴─────────┴─────────┴─────────┴──────────┴────────────┴───────────┴───────────┴────────┴─────────────────┘\n\nYou can then use GroupTestToDataframe to get DataFrame of CLD:\n\njulia> GroupTestToDataframe(result)\n3×3 DataFrame\n Row │ GroupIndex  GroupLabel  CLD    \n     │ Int64       String      String \n─────┼────────────────────────────────\n   1 │          1  Ctrl        b\n   2 │          2  TrtA        a\n   3 │          3  TrtB        b\n\nYou can get the PostHoc Details use DataFrame:\n\njulia> DataFrame(result)\n3×10 DataFrame\n Row │ Contrast     Diff     Std.Err  Stat     Critical  P-value     Lower 95%   Upper 95%   Sig     Note            \n     │ String       Float64  Float64  Float64  Float64   Float64     Float64     Float64     String  String          \n─────┼───────────────────────────────────────────────────────────────────────────────────────────────────────────────\n   1 │ Ctrl - TrtA    -19.6    3.937   4.9784   2.39398  1.92331e-6  -29.0251    -10.1749    *       Adj: Bonferroni\n   2 │ Ctrl - TrtB     -9.2    3.937   2.3368   2.39398  0.0583484   -18.6251      0.225108          Adj: Bonferroni\n   3 │ TrtA - TrtB     10.4    3.937   2.6416   2.39398  0.0247544     0.974892   19.8251    *       Adj: Bonferroni","category":"section"},{"location":"lib/public/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"lib/public/#New-Hypothesis-Tests","page":"API Reference","title":"New Hypothesis Tests","text":"","category":"section"},{"location":"lib/public/#Post-Hoc-Analysis","page":"API Reference","title":"Post-Hoc Analysis","text":"","category":"section"},{"location":"lib/public/#Parametric-and-Non-Parametric","page":"API Reference","title":"Parametric & Non-Parametric","text":"","category":"section"},{"location":"lib/public/#Contingency-Tables","page":"API Reference","title":"Contingency Tables","text":"","category":"section"},{"location":"lib/public/#Structures-and-Results","page":"API Reference","title":"Structures & Results","text":"","category":"section"},{"location":"lib/public/#DataFrame-Extensions","page":"API Reference","title":"DataFrame Extensions","text":"Note: These methods extend HypothesisTests.jl functions to accept DataFrame as inputs.","category":"section"},{"location":"lib/public/#Categorical-Tests","page":"API Reference","title":"Categorical Tests","text":"","category":"section"},{"location":"lib/public/#K-Sample-and-Variance-Tests","page":"API Reference","title":"K-Sample & Variance Tests","text":"","category":"section"},{"location":"lib/public/#Two-Sample-Tests","page":"API Reference","title":"Two-Sample Tests","text":"","category":"section"},{"location":"lib/public/#HypothesisTestsExtra.WelchANOVATest","page":"API Reference","title":"HypothesisTestsExtra.WelchANOVATest","text":"WelchANOVATest(groups)\nWelchANOVATest(groups::AbstractVector{<:Real}...)\nWelchANOVATest(df::DataFrame, group_col::Symbol, data_col::Symbol)\n\nPerform Welch's ANOVA test of the hypothesis that the groups means are equal. This test is an alternative to the standard One-Way ANOVA when the assumption of  equal variances (homoscedasticity) is violated.\n\nThe test statistic is approximately F-distributed.\n\nImplements: pvalue\n\nExample\n\n# input arrays\nWelchANOVATest(randn(10), randn(15).+1, randn(12).+2)\n\n# input DataFrame\nusing StatsBase, DataFrames\ncdf = DataFrame(A = sample([\"G1\",\"G2\"], 100), B = sample(randn(10), 100))\nWelchANOVATest(cdf, :A, :B)\n\nExternal links\n\nWelch's t-test and ANOVA on Wikipedia\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#HypothesisTestsExtra.FisherExactTestRxC","page":"API Reference","title":"HypothesisTestsExtra.FisherExactTestRxC","text":"FisherExactTestRxC(tbl::AbstractMatrix{<:Integer})\n\nA smart constructor that acts as a drop-in replacement for Fisher's Exact Test.\n\nIf tbl is 2x2, it returns a standard HypothesisTests.FisherExactTest object  (calculating the exact p-value deterministically and supporting Odds Ratio CI).\nIf tbl is RxC (where R>2 or C>2), it returns a FisherExactTestMC object  (estimating the p-value via Monte Carlo simulation).\n\n\n\n\n\nFisherExactTestRxC(df::DataFrame, row_col::Symbol, col_col::Symbol)\n\nCompute Fisher's Exact Test for general RxC tables from a raw DataFrame.\n\nThis function aggregates the DataFrame columns into a contingency table and then applies FisherExactTestRxC.\n\nIf the resulting table is 2x2, it calculates the exact p-value.\nIf the resulting table is RxC (larger than 2x2), it estimates the p-value via Monte Carlo simulation.\n\nArguments\n\ndf: DataFrame containing raw observations.\nrow_col: Column determining the table rows.\ncol_col: Column determining the table columns.\n\n\n\n\n\nFisherExactTestRxC(df::DataFrame, row_col::Symbol, col_col::Symbol, freq_col::Symbol)\n\nCompute Fisher's Exact Test (RxC or 2x2) from aggregated frequency data (Long format).\n\n\n\n\n\n","category":"function"},{"location":"lib/public/#HypothesisTestsExtra.FisherExactTestMC","page":"API Reference","title":"HypothesisTestsExtra.FisherExactTestMC","text":"FisherExactTestMC(tbl::AbstractMatrix{<:Integer})\n\nInternal struct for performing Monte Carlo Fisher's exact test on R x C tables. Users should generally use FisherExactTestRxC which automatically selects between this and the exact 2x2 test.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#HypothesisTestsExtra.PostHocTest","page":"API Reference","title":"HypothesisTestsExtra.PostHocTest","text":"PostHocTest(groups; method=:tukey, alpha=0.05, alpha_levene=0.05, cld=false, pairs=nothing, row_labels=[])\n\nPerform parametric post-hoc pairwise comparisons (Multiple Comparison Procedures) on a set of data groups.\n\nArguments\n\ngroups::AbstractVector{<:AbstractVector{<:Real}}: A vector of vectors, where each inner vector contains the numerical observations for a specific group.\n\nKeyword Arguments\n\nmethod::Symbol: The post-hoc algorithm to use. Defaults to :tukey. See the Supported Methods section below for details on each option.\nalpha::Float64: The significance level (Type I error rate) for the hypothesis tests and confidence intervals. Defaults to 0.05.\nalpha_levene::Float64: The threshold used for the internal Levene's test. If the p-value of Levene's test is below this value, a warning is issued suggesting the data has unequal variances (heteroscedasticity) and recommending :tamhane. Defaults to 0.05.\ncld::Bool: If true, generates Compact Letter Display (CLD) codes. Groups sharing the same letter are not significantly different. Defaults to false.\npairs: An optional Vector{Tuple{Int, Int}} specifying a subset of group indices to compare (e.g., [(1, 2), (1, 3)]). If nothing (default), all possible pairwise combinations are tested.\nrow_labels: Optional vector of strings to label the groups in the output. If empty, defaults to \"Group1\", \"Group2\", etc.\n\nSupported Methods\n\nThe method argument accepts the following symbols:\n\n1. Equal Variance Assumed (Homoscedasticity):\n\n:tukey (Default): Tukey's HSD (Honest Significant Difference).   Based on the Studentized Range distribution. It controls the Family-Wise Error Rate (FWER) for all pairwise comparisons. It is the standard choice for balanced or slightly unbalanced designs.\n:lsd: Fisher's LSD (Least Significant Difference).   Performs individual t-tests without FWER adjustment. It is the most powerful (least conservative) but carries a high risk of Type I errors (false positives) as the number of groups increases.\n:bonferroni: Bonferroni Correction.   Adjusts the significance level to alpha / m (where m is the number of tests). It is very conservative and strictly controls FWER, but often lacks power.\n:sidak: Sidak Correction.   Adjusts the significance level to 1 - (1 - alpha)^(1/m). It is slightly more powerful than Bonferroni while maintaining strict FWER control (assuming independence).\n:scheffe: Scheffe's Method.   Based on the F-distribution. It is designed to control FWER for all possible linear contrasts, not just pairwise comparisons. Consequently, it is extremely conservative for simple pairwise tests.\n:snk: Student-Newman-Keuls.   A stepwise multiple range procedure. It adjusts the critical value based on the number of steps between means. It is less conservative than Tukey but does not strictly control FWER in the strong sense.\n:duncan: Duncan's New Multiple Range Test.   Similar to SNK but uses a more liberal protection level. It has higher power but a higher rate of Type I errors compared to SNK or Tukey.\n\n2. Unequal Variance Assumed (Heteroscedasticity):\n\n:tamhane: Tamhane's T2.   Uses Welch's t-test (which adjusts degrees of freedom for unequal variances) combined with a Sidak-like multiplicative correction for the p-value. This is the recommended method when Levene's test is significant.\n\nReturns\n\nReturns a PostHocTestResult object containing detailed comparison statistics (diff, standard error, test statistic, critical value, p-value, confidence intervals) and CLD letters if requested.\n\nExample\n\nPostHocTest([randn(10), randn(10).+5, randn(10).+0.1]; cld = true, row_labels=[\"Control\", \"TreatA\", \"TreatB\"])\n\n\n\n\n\nPostHocTest(df::DataFrame, group_col::Symbol, data_col::Symbol; kwargs...)\n\nPerform parametric post-hoc pairwise comparisons (e.g., Tukey's HSD) directly on a DataFrame.\n\nArguments\n\ndf: The DataFrame containing the raw data.\ngroup_col: Symbol representing the column with group labels.\ndata_col: Symbol representing the column with numerical observations.\nkwargs: Arguments passed to the core PostHocTest function.\n\n\n\n\n\n","category":"function"},{"location":"lib/public/#HypothesisTestsExtra.PostHocNonPar","page":"API Reference","title":"HypothesisTestsExtra.PostHocNonPar","text":"PostHocNonPar(groups; method=:dunn_bonferroni, alpha=0.05, cld=false, pairs=nothing, row_labels=[])\n\nPerform non-parametric post-hoc pairwise comparisons on a set of data groups.  This function is typically used after a significant Kruskal-Wallis test to determine which specific groups differ. It operates on the ranks of the data rather than the raw values.\n\nArguments\n\ngroups::AbstractVector{<:AbstractVector{<:Real}}: A vector of vectors, where each inner vector contains the numerical observations for a specific group.\n\nKeyword Arguments\n\nmethod::Symbol: The post-hoc algorithm to use. Defaults to :dunn_bonferroni. See the Supported Methods section below for details.\nalpha::Float64: The significance level (Type I error rate). Defaults to 0.05.\ncld::Bool: If true, generates Compact Letter Display (CLD) codes based on the rank comparisons. Groups sharing the same letter are not significantly different. Defaults to false.\npairs: An optional Vector{Tuple{Int, Int}} specifying a subset of group indices to compare. If nothing (default), all possible pairwise combinations are tested.\nrow_labels: Optional vector of strings to label the groups in the output. If empty, defaults to \"Group1\", \"Group2\", etc.\n\nSupported Methods\n\nThe method argument accepts the following symbols. All methods automatically apply a tie correction factor to the standard error if ties are present in the data.\n\n1. Dunn's Test (Z-test based): Dunn's test approximates the distribution of the difference in mean ranks using a normal distribution (Z-test). It allows for various p-value adjustment methods to control the Family-Wise Error Rate (FWER).\n\n:dunn: Unadjusted Dunn's Test.   Performs raw comparisons without correcting for multiple testing. High power but high risk of Type I errors (false positives).\n:dunn_bonferroni (Default): Dunn's Test with Bonferroni Correction.   Adjusts p-values by multiplying by the number of tests. Strict FWER control, conservative.\n:dunn_sidak: Dunn's Test with Sidak Correction.   Adjusts p-values using 1 - (1 - p)^m. Slightly more powerful than Bonferroni while maintaining FWER control.\n\n2. Nemenyi Test (Studentized Range based):\n\n:nemenyi: Nemenyi Test.   This is the non-parametric equivalent of Tukey's HSD. It uses the Studentized Range distribution (approximated with infinite degrees of freedom) to determine critical values. It controls FWER for all pairwise comparisons and is generally more conservative than Dunn's test, especially for large numbers of groups.\n\nReturns\n\nReturns a PostHocTestResult object containing detailed comparison statistics (diff in mean ranks, standard error, Z/Q statistic, critical value, p-value, confidence intervals) and CLD letters if requested.\n\nExample\n\n# 3 groups with different distributions\ng1 = rand(10)\ng2 = rand(10) .+ 2\ng3 = rand(10) .+ 0.5\n\n# Perform Dunn's test with Bonferroni correction and generate CLD letters\nresult = PostHocNonPar([g1, g2, g3]; method=:dunn_bonferroni, cld=true, row_labels=[\"Ctrl\", \"TrtA\", \"TrtB\"])\n\n\n\n\n\nPostHocNonPar(df::DataFrame, group_col::Symbol, data_col::Symbol; kwargs...)\n\nPerform non-parametric post-hoc pairwise comparisons (e.g., Dunn's Test) directly on a DataFrame.\n\nArguments\n\ndf: The DataFrame containing the raw data.\ngroup_col: Symbol representing the column with group labels.\ndata_col: Symbol representing the column with numerical observations.\nkwargs: Arguments passed to the core PostHocNonPar function (e.g., method, alpha, p_adjust).\n\n\n\n\n\n","category":"function"},{"location":"lib/public/#HypothesisTestsExtra.PostHocContingencyRow","page":"API Reference","title":"HypothesisTestsExtra.PostHocContingencyRow","text":"PostHocContingencyRow(table::AbstractMatrix{<:Integer}; method=:chisq, adjustment=:bonferroni, cld=false, alpha=0.05, pairs=nothing, row_labels=[])\n\nPerform pairwise comparisons between rows of a contingency table to identify which groups differ significantly in their distribution across columns.\n\nArguments\n\ntable::AbstractMatrix{<:Integer}: The RxC contingency table.\n\nKeyword Arguments\n\nmethod::Symbol: The statistical test to use for pairwise comparisons.\n:chisq (Default): Pearson's Chi-square test. Fast and standard for large samples.\n:fisher: Fisher's Exact Test. \nFor 2x2 sub-tables, it computes the exact p-value.\nFor 2xC sub-tables (where C > 2), it estimates the p-value via Monte Carlo simulation (see FisherExactTestRxC).\nadjustment::Symbol: The method to adjust p-values for multiple comparisons.\n:bonferroni: Strong control of FWER (p * m).\n:bh (or :fdr): Benjamini-Hochberg procedure for False Discovery Rate control.\n:none: No adjustment.\nalpha::Float64: Significance level. Defaults to 0.05.\ncld::Bool: If true, generates Compact Letter Display codes based on the proportion of the first column. Defaults to false.\npairs: An optional Vector{Tuple{Int, Int}} specifying a subset of row indices to compare (e.g., [(1, 2), (1, 3)]). If nothing (default), all possible pairwise combinations are tested.\nrow_labels: Optional vector of strings to label the rows in the output.\n\nReturns\n\nReturns a PostHocTestResult object containing comparison statistics and adjusted p-values.\n\nExample\n\nusing HypothesisTests\n\n# Data: 4 Groups (Rows) vs 3 Outcomes (Cols: Success, Neutral, Fail)\n# Group 1 and 2 are similar, Group 3 is different, Group 4 is very different\ntable = [\n    50 30 20; # Group 1\n    48 32 20; # Group 2 (Similar to 1)\n    20 40 40; # Group 3 (Different)\n    10 10 80  # Group 4 (Very different)\n]\nrow_labs = [\"Grp1\", \"Grp2\", \"Grp3\", \"Grp4\"]\n\n# 1. Standard Pairwise Chi-Square with Bonferroni adjustment\n# Also requesting Compact Letter Display (cld=true)\nres_chisq = PostHocContingencyRow(table, method=:chisq, adjustment=:bonferroni, \n                                  cld=true, row_labels=row_labs)\n\n# Inspect the Compact Letter Display (if generated)\n# println(res_chisq.letters) \n# Expected: Grp1 and Grp2 might share a letter (e.g., \"a\"), Grp3 \"b\", Grp4 \"c\"\n\n# 2. Pairwise Fisher's Exact Test (Robust for small counts and supports RxC)\n# Only comparing Group 1 vs Group 4 and Group 1 vs Group 3\nspecific_pairs = [(1, 4), (1, 3)]\nres_fisher = PostHocContingencyRow(table, method=:fisher, adjustment=:none,\n                                   pairs=specific_pairs, row_labels=row_labs)\n\n# Print p-values for the specific pairs\nfor cmp in res_fisher.comparisons\n    println(\"Comparing $(row_labs[cmp.idx_a]) vs $(row_labs[cmp.idx_b]): p = $(cmp.p_val)\")\nend\n\n\n\n\n\nPostHocContingencyRow(df::DataFrame, row_col::Symbol, col_col::Symbol; kwargs...)\n\nPerform row-wise post-hoc comparisons (e.g., Chi-Sq or Fisher) on raw categorical data. The function automatically aggregates the data into a contingency table (counts) before analysis.\n\nArguments\n\ndf: DataFrame containing raw observations (one row per subject).\nrow_col: Column determining the table rows (groups to compare).\ncol_col: Column determining the table columns (outcomes).\n\n\n\n\n\nPostHocContingencyRow(df::DataFrame, row_col::Symbol, col_col::Symbol, freq_col::Symbol; kwargs...)\n\nPerform row-wise post-hoc comparisons on aggregated frequency data (Long format).\n\nArguments\n\ndf: DataFrame containing aggregated counts.\nrow_col: Column determining the table rows.\ncol_col: Column determining the table columns.\nfreq_col: Column containing the integer counts/frequencies.\n\nProcess\n\nPivots the DataFrame into a matrix (using unstack), filling missing combinations with 0, then calls the core logic.\n\n\n\n\n\n","category":"function"},{"location":"lib/public/#HypothesisTestsExtra.PostHocContingencyCell","page":"API Reference","title":"HypothesisTestsExtra.PostHocContingencyCell","text":"PostHocContingencyCell(table::AbstractMatrix{<:Integer}; method=:asr, adjustment=:bonferroni, alpha=0.05, row_labels=[], col_labels=[])\n\nPerform cell-level post-hoc analysis on a contingency table to identify specific cells that contribute significantly to the overall association.\n\nArguments\n\ntable: RxC contingency table (Matrix of Integers).\nmethod: \n:asr: Adjusted Standardized Residuals. Tests if a cell deviates from independence.\n:fisher_1vsall: Fisher's Exact Test for each cell (One vs Rest).\nadjustment::Symbol: The method to adjust p-values for multiple comparisons.\n:bonferroni: Strong control of FWER (p * m).\n:bh (or :fdr): Benjamini-Hochberg procedure for False Discovery Rate control.\n:none: No adjustment.\nrow_labels: Optional vector of strings for row names.\ncol_labels: Optional vector of strings for column names.\n\nReturns\n\nA ContingencyCellTestResult object containing matrices for statistics, raw p-values, adjusted p-values, and significance flags.\n\nExamples\n\nusing HypothesisTests, Distributions\n\n# Create a 3x3 contingency table (e.g., 3 Age Groups vs 3 Preferences)\n# Rows: Young, Middle, Old\n# Cols: Option A, Option B, Option C\ntable = [\n    30 10 10;  # Young mostly prefer A\n    10 30 10;  # Middle mostly prefer B\n    10 10 30   # Old mostly prefer C\n]\nr_labs = [\"Young\", \"Middle\", \"Old\"]\nc_labs = [\"Opt_A\", \"Opt_B\", \"Opt_C\"]\n\n# 1. Use Adjusted Standardized Residuals (ASR) with Bonferroni correction\nres_asr = PostHocContingencyCell(table, method=:asr, adjustment=:bonferroni,\n                                 row_labels=r_labs, col_labels=c_labs)\n\n# Check the matrix of adjusted residuals (Z-scores)\n# println(res_asr.stats_mat)\n\n# Check which cells are significant (True/False matrix)\n# println(res_asr.sig_mat)\n\n# 2. Use One-vs-Rest Fisher's Exact Test with FDR (Benjamini-Hochberg) adjustment\nres_fisher = PostHocContingencyCell(table, method=:fisher_1vsall, adjustment=:bh,\n                                    row_labels=r_labs, col_labels=c_labs)\n\n\n\n\n\nPostHocContingencyCell(df::DataFrame, row_col::Symbol, col_col::Symbol; kwargs...)\n\nPerform cell-level post-hoc analysis (e.g., ASR) on raw categorical data.\n\nThe function automatically aggregates the data into a contingency table (counts) before analysis.\n\nArguments\n\ndf: DataFrame containing raw observations (one row per subject).\nrow_col: Column determining the table rows (groups to compare).\ncol_col: Column determining the table columns (outcomes).\n\n\n\n\n\nPostHocContingencyCell(df::DataFrame, row_col::Symbol, col_col::Symbol, freq_col::Symbol; kwargs...)\n\nPerform cell-level post-hoc analysis on aggregated frequency data (Long format).\n\nArguments\n\ndf: DataFrame containing aggregated counts.\nrow_col: Column determining the table rows.\ncol_col: Column determining the table columns.\nfreq_col: Column containing the integer counts/frequencies.\n\n\n\n\n\n","category":"function"},{"location":"lib/public/#HypothesisTestsExtra.PostHocTestResult","page":"API Reference","title":"HypothesisTestsExtra.PostHocTestResult","text":"PostHocTestResult\n\nContainer for the results of a post-hoc multiple comparison test.\n\nFields\n\nmethod::Symbol: The name of the post-hoc method used (e.g., :tukey, :bonferroni).\ncomparisons::Vector{PostHocComparison}: A list of all pairwise comparisons performed.\nalpha::Float64: The significance level used for the test (e.g., 0.05).\nuse_cld::Bool: Whether Compact Letter Display (CLD) was calculated.\ncld_letters::Dict{Int, String}: Mapping of group indices to CLD letters (if applicable).\nlabel_map::Dict{Int, String}: Mapping of internal group indices back to original labels (e.g., \"Control\", \"Treat\").\n\nMethods\n\nDataFrame(res): Convert detailed pairwise results to a DataFrame.\nGroupTestToDataframe(res): Convert CLD results to a DataFrame.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#HypothesisTestsExtra.PostHocComparison","page":"API Reference","title":"HypothesisTestsExtra.PostHocComparison","text":"PostHocComparison\n\nStores the statistical results of a single pairwise comparison between two groups.\n\nFields\n\ngroup1::Int: Index of the first group in the comparison.\ngroup2::Int: Index of the second group in the comparison.\ndiff::Float64: The difference between means (Group1 - Group2).\nse::Float64: Standard Error of the difference.\nstatistic::Float64: Test statistic (e.g., t-value or q-value).\ncrit_val::Float64: Critical value for the test statistic at the specified alpha.\np_value::Float64: Calculated p-value for the comparison.\nlower_ci::Float64: Lower bound of the confidence interval.\nupper_ci::Float64: Upper bound of the confidence interval.\nrejected::Bool: Boolean flag indicating if the null hypothesis was rejected (significant difference).\nnote::String: Additional annotations or warnings (e.g., \"ns\", \"***\").\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#HypothesisTestsExtra.ContingencyCellTestResult","page":"API Reference","title":"HypothesisTestsExtra.ContingencyCellTestResult","text":"ContingencyCellTestResult\n\nStores the results of post-hoc cell-wise analysis for contingency tables (e.g., Adjusted Standardized Residuals).\n\nFields\n\nmethod::Symbol: The method used for cell analysis (e.g., :asr for Adjusted Standardized Residuals).\nadjust_method::Symbol: P-value adjustment method for multiple comparisons (e.g., :bonferroni, :fdr).\nobserved::Matrix{Int}: The original matrix of observed counts.\nstats_matrix::Matrix{Float64}: Matrix of test statistics (e.g., Z-scores for ASR or Odds Ratios).\npvals_matrix::Matrix{Float64}: Matrix of raw p-values.\nadj_pvals_matrix::Matrix{Float64}: Matrix of adjusted p-values.\nsig_matrix::Matrix{Bool}: Boolean matrix indicating significance at the given alpha level.\nalpha::Float64: Significance level.\nrow_labels::Vector{String}: Labels for the rows of the contingency table.\ncol_labels::Vector{String}: Labels for the columns of the contingency table.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#HypothesisTestsExtra.GroupTestToDataframe","page":"API Reference","title":"HypothesisTestsExtra.GroupTestToDataframe","text":"GroupTestToDataframe(res::PostHocTestResult)\n\nGet CLD (Compact Letter Display) labels of PostHocTestResult as a DataFrame. Returns columns: GroupIndex, GroupLabel, and CLD.\n\n\n\n\n\n","category":"function"},{"location":"lib/public/#HypothesisTestsExtra.CellTestToDataframe","page":"API Reference","title":"HypothesisTestsExtra.CellTestToDataframe","text":"CellTestToDataframe(res::ContingencyCellTestResult)\n\nGenerate a matrix-form DataFrame from ContingencyCellTestResult. Cell content format is \"Value*\" (if significant) or \"Value\".\n\n\n\n\n\n","category":"function"},{"location":"lib/public/#HypothesisTests.ChisqTest-Tuple{DataFrame, Symbol, Symbol}","page":"API Reference","title":"HypothesisTests.ChisqTest","text":"ChisqTest(df::DataFrame, row_col::Symbol, col_col::Symbol)\n\nCompute Pearson's Chi-square test from a raw DataFrame. Generates a contingency table internally. Requires at least a 2x2 table.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#HypothesisTests.ChisqTest-Tuple{DataFrame, Symbol, Symbol, Symbol}","page":"API Reference","title":"HypothesisTests.ChisqTest","text":"ChisqTest(df::DataFrame, row_col::Symbol, col_col::Symbol, freq_col::Symbol)\n\nCompute Pearson's Chi-square test from aggregated frequency data (Long format).\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#HypothesisTests.FisherExactTest-Tuple{DataFrame, Symbol, Symbol}","page":"API Reference","title":"HypothesisTests.FisherExactTest","text":"FisherExactTest(df::DataFrame, row_col::Symbol, col_col::Symbol)\n\nCompute Fisher's Exact Test from a raw DataFrame. Currently supports only 2x2 tables. For RxC tables, use FisherExactTestRxC, which supports both the Monte Carlo Fisher's exact test (RxC) and the exact 2x2 test.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#HypothesisTests.FisherExactTest-Tuple{DataFrame, Symbol, Symbol, Symbol}","page":"API Reference","title":"HypothesisTests.FisherExactTest","text":"FisherExactTest(df::DataFrame, row_col::Symbol, col_col::Symbol, freq_col::Symbol)\n\nCompute Fisher's Exact Test (2x2) from aggregated frequency data (Long format).\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#HypothesisTests.PowerDivergenceTest-Tuple{DataFrame, Symbol, Symbol}","page":"API Reference","title":"HypothesisTests.PowerDivergenceTest","text":"PowerDivergenceTest(df::DataFrame, row_col::Symbol, col_col::Symbol; lambda::Real=1.0)\n\nCompute Power Divergence Test (e.g., G-test if lambda=0) from a raw DataFrame.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#HypothesisTests.PowerDivergenceTest-Tuple{DataFrame, Symbol, Symbol, Symbol}","page":"API Reference","title":"HypothesisTests.PowerDivergenceTest","text":"PowerDivergenceTest(df::DataFrame, row_col::Symbol, col_col::Symbol, freq_col::Symbol; lambda::Real=1.0)\n\nCompute Power Divergence Test from aggregated frequency data (Long format).\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#HypothesisTests.OneWayANOVATest-Tuple{DataFrame, Symbol, Symbol}","page":"API Reference","title":"HypothesisTests.OneWayANOVATest","text":"OneWayANOVATest(df::DataFrame, group_col::Symbol, data_col::Symbol)\n\nPerform One-Way ANOVA to test equality of means across groups in a DataFrame.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#HypothesisTests.KruskalWallisTest-Tuple{DataFrame, Symbol, Symbol}","page":"API Reference","title":"HypothesisTests.KruskalWallisTest","text":"KruskalWallisTest(df::DataFrame, group_col::Symbol, data_col::Symbol)\n\nPerform Kruskal-Wallis Rank Sum Test (non-parametric ANOVA) on a DataFrame.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#HypothesisTests.LeveneTest-Tuple{DataFrame, Symbol, Symbol}","page":"API Reference","title":"HypothesisTests.LeveneTest","text":"LeveneTest(df::DataFrame, group_col::Symbol, data_col::Symbol)\n\nPerform Levene's Test for equality of variances across groups in a DataFrame.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#HypothesisTests.BrownForsytheTest-Tuple{DataFrame, Symbol, Symbol}","page":"API Reference","title":"HypothesisTests.BrownForsytheTest","text":"BrownForsytheTest(df::DataFrame, group_col::Symbol, data_col::Symbol)\n\nPerform Brown-Forsythe Test (robust Levene's test using median) for equality of variances.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#HypothesisTests.FlignerKilleenTest-Tuple{DataFrame, Symbol, Symbol}","page":"API Reference","title":"HypothesisTests.FlignerKilleenTest","text":"FlignerKilleenTest(df::DataFrame, group_col::Symbol, data_col::Symbol)\n\nPerform Fligner-Killeen Test (non-parametric) for equality of variances.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#HypothesisTests.EqualVarianceTTest-Tuple{DataFrame, Symbol, Symbol}","page":"API Reference","title":"HypothesisTests.EqualVarianceTTest","text":"EqualVarianceTTest(df::DataFrame, group_col::Symbol, data_col::Symbol)\n\nPerform Student's T-Test (assuming equal variance) between exactly two groups in a DataFrame.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#HypothesisTests.UnequalVarianceTTest-Tuple{DataFrame, Symbol, Symbol}","page":"API Reference","title":"HypothesisTests.UnequalVarianceTTest","text":"UnequalVarianceTTest(df::DataFrame, group_col::Symbol, data_col::Symbol)\n\nPerform Welch's T-Test (not assuming equal variance) between exactly two groups in a DataFrame.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#HypothesisTests.VarianceFTest-Tuple{DataFrame, Symbol, Symbol}","page":"API Reference","title":"HypothesisTests.VarianceFTest","text":"VarianceFTest(df::DataFrame, group_col::Symbol, data_col::Symbol)\n\nPerform F-Test to compare the variances of exactly two groups in a DataFrame.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#HypothesisTests.MannWhitneyUTest-Tuple{DataFrame, Symbol, Symbol}","page":"API Reference","title":"HypothesisTests.MannWhitneyUTest","text":"MannWhitneyUTest(df::DataFrame, group_col::Symbol, data_col::Symbol)\n\nPerform Mann-Whitney U Test (Wilcoxon Rank Sum) between exactly two groups in a DataFrame.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#HypothesisTests.ApproximateTwoSampleKSTest-Tuple{DataFrame, Symbol, Symbol}","page":"API Reference","title":"HypothesisTests.ApproximateTwoSampleKSTest","text":"ApproximateTwoSampleKSTest(df::DataFrame, group_col::Symbol, data_col::Symbol)\n\nPerform Approximate Two-Sample Kolmogorov-Smirnov Test between exactly two groups in a DataFrame.\n\n\n\n\n\n","category":"method"},{"location":"#HypothesisTestsExtra.jl","page":"Home","title":"HypothesisTestsExtra.jl","text":"HypothesisTestsExtra.jl is an extension library for the Julia ecosystem's standard HypothesisTests.jl. It fills critical gaps in statistical analysis by providing robust support for:\n\nHeteroscedastic Data: Welch's ANOVA for unequal variances.\nComplex Categorical Data: Fisher's Exact Test for R times C tables via Monte Carlo simulation.\nPost-Hoc Analysis: A comprehensive suite of pairwise comparison tools (Parametric, Non-Parametric, and Contingency tables) with support for Compact Letter Displays (CLD).\nDataFrames Integration: Native support for passing DataFrame objects to both standard and new hypothesis tests.","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"using Pkg\nPkg.add(\"HypothesisTestsExtra\")","category":"section"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"using HypothesisTestsExtra, DataFrames\n\n# 1. Welch ANOVA (Unequal Variances)\ngroups = [[1,2,3], [10,11,12], [5,6,7]]\nwt = WelchANOVATest(groups...)\n\n# 2. Post-Hoc Test with Tukey's HSD\nph = PostHocTest(groups; method=:tukey, cld=true)\nprintln(ph)\n\n# 3. DataFrame Support\ndf = DataFrame(Group=[\"A\",\"A\",\"B\",\"B\"], Value=[1,2, 10,11])\nPostHocTest(df, :Group, :Value; method=:tukey)","category":"section"},{"location":"man/dataframes/#DataFrame-Integration","page":"DataFrame Integration","title":"DataFrame Integration","text":"HypothesisTestsExtra.jl extends the dispatch of HypothesisTests.jl to allow direct usage of DataFrames.DataFrame. This eliminates the need to manually extract vectors or pivot tables before testing.","category":"section"},{"location":"man/dataframes/#Supported-Functions","page":"DataFrame Integration","title":"Supported Functions","text":"","category":"section"},{"location":"man/dataframes/#1.-Standard-Hypothesis-Tests","page":"DataFrame Integration","title":"1. Standard Hypothesis Tests","text":"The library adds DataFrame support to existing tests in HypothesisTests.jl:\n\nT-Tests: EqualVarianceTTest, UnequalVarianceTTest\nVariance: LeveneTest, BrownForsytheTest, FlignerKilleenTest\nDistribution: KruskalWallisTest, MannWhitneyUTest\nCategorical: ChisqTest, FisherExactTest\n\nSyntax Pattern:\n\nTestName(df::DataFrame, group_col::Symbol, data_col::Symbol)\n\nExample:\n\nusing DataFrames\ndf = DataFrame(\n    Gender = [\"M\", \"F\", \"M\", \"F\", \"M\"],\n    Score  = [90, 92, 88, 95, 85]\n)\n\n# Test if Score differs by Gender\nUnequalVarianceTTest(df, :Gender, :Score)\n\nYou will get:\n\nTwo sample t-test (unequal variance)\n------------------------------------\nPopulation details:\n    parameter of interest:   Mean difference\n    value under h_0:         0\n    point estimate:          5.83333\n    95% confidence interval: (-1.414, 13.08)\n\nTest summary:\n    outcome with 95% confidence: fail to reject h_0\n    two-sided p-value:           0.0800\n\nDetails:\n    number of observations:   [2,3]\n    t-statistic:              2.7933040956366755\n    degrees of freedom:       2.6086358344798386\n    empirical standard error: 2.088327347690278","category":"section"},{"location":"man/dataframes/#2.-Contingency-Tables-from-DataFrames","page":"DataFrame Integration","title":"2. Contingency Tables from DataFrames","text":"You can perform categorical tests on DataFrames in two formats:\n\nA. Raw Data (Long Format) One row per observation.\n\ndf_raw = DataFrame(Treatment=[\"A\", \"A\", \"B\"], Outcome=[\"Success\", \"Fail\", \"Success\"])\nChisqTest(df_raw, :Treatment, :Outcome)\n\nB. Frequency Data (Aggregated) One row per combination, with a count column.\n\ndf_freq = DataFrame(Treatment=[\"A\", \"B\"], Outcome=[\"Win\", \"Win\"], Count=[10, 20])\n# Pass the frequency column as the 3rd argument\nChisqTest(df_freq, :Treatment, :Outcome, :Count)","category":"section"},{"location":"man/dataframes/#3.-Post-Hoc-on-DataFrames","page":"DataFrame Integration","title":"3. Post-Hoc on DataFrames","text":"The new Post-Hoc methods fully support the DataFrame interface.\n\n# Parametric\nPostHocTest(df, :Group, :Value; method=:tukey, cld=true)\n\n# Contingency Row-wise\nPostHocContingencyRow(df, :RowCat, :ColCat; method=:chisq)","category":"section"}]
}
